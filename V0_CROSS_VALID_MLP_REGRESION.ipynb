{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPzhSa/B+iPLz3cTp+dfygu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DYNAFEM/REGRESION-PESO-BOVINOS/blob/MODELOS-MLP-REGRESOR/V0_CROSS_VALID_MLP_REGRESION.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Importar Librerias Necesarias"
      ],
      "metadata": {
        "id": "XLYEtEKmLLOx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DmVYlTuzvSMO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner\n",
        "import keras_tuner as kt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCtdyXrudfHl",
        "outputId": "59d5bc7e-6fb5-4451-e886-16deabc13644"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.12/dist-packages (from keras-tuner) (3.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from keras-tuner) (25.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from keras-tuner) (2.32.4)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from keras->keras-tuner) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras->keras-tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras->keras-tuner) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from keras->keras-tuner) (3.15.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras->keras-tuner) (0.17.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.12/dist-packages (from keras->keras-tuner) (0.5.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->keras-tuner) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->keras-tuner) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->keras-tuner) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->keras-tuner) (2025.10.5)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from optree->keras->keras-tuner) (4.15.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras->keras-tuner) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras->keras-tuner) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "# Montar Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVlY98OZAaEh",
        "outputId": "352a50b0-a829-4979-ff69-e649620ce63a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Montar Datos y Separar Predictora"
      ],
      "metadata": {
        "id": "0Au4WJJU_cdq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reproducibilidad\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)"
      ],
      "metadata": {
        "id": "-ZkKy-NRnkp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar datos procesados\n",
        "ruta_train = '/content/drive/My Drive/REGRESION_PESO/DATOS_TRAIN_TEST_STANDARD/train_dataset.csv'\n",
        "ruta_test = '/content/drive/My Drive/REGRESION_PESO/DATOS_TRAIN_TEST_STANDARD/test_dataset.csv'\n",
        "\n",
        "train_df = pd.read_csv(ruta_train)\n",
        "test_df = pd.read_csv(ruta_test)\n",
        "\n",
        "# Separar datos\n",
        "X_train = train_df.drop(columns=['weight_in_kg'])\n",
        "y_train = train_df['weight_in_kg']\n",
        "\n",
        "X_test = test_df.drop(columns=['weight_in_kg'])\n",
        "y_test = test_df['weight_in_kg']"
      ],
      "metadata": {
        "id": "sW0pxQYq_brL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.head())\n",
        "print(X_train.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "cAV4qw5mDFqT",
        "outputId": "569f6009-3e14-4273-ee5c-e4d6650ed4f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   age_in_year     teeth  height_in_inch     price  sex_MALE_BULL  color_RED  \\\n",
            "0     1.643310  1.653526       -0.948784 -0.242195       0.121867   0.829001   \n",
            "1    -0.551338 -0.547596        0.523196  0.014779       0.121867   0.829001   \n",
            "2    -0.551338 -0.547596       -0.059463 -0.587513       0.121867   0.829001   \n",
            "3    -0.551338 -0.547596       -1.102116 -0.270972       0.121867   0.829001   \n",
            "4    -0.551338 -0.547596       -1.102116 -0.645066       0.121867   0.829001   \n",
            "\n",
            "   breed_HOSTINE_CROSS  breed_LOCAL  breed_MIR_KADIM  breed_PABNA_BREED  \\\n",
            "0            -0.260208     0.677551        -0.070014          -0.099258   \n",
            "1            -0.260208     0.677551        -0.070014          -0.099258   \n",
            "2            -0.260208     0.677551        -0.070014          -0.099258   \n",
            "3            -0.260208     0.677551        -0.070014          -0.099258   \n",
            "4            -0.260208     0.677551        -0.070014          -0.099258   \n",
            "\n",
            "   breed_RED_CHITTAGONG  breed_SAHIWAL  breed_SINDHI  size_LARGE  size_MEDIUM  \\\n",
            "0             -0.201517      -0.372678      -0.27589   -0.265511    -1.269435   \n",
            "1             -0.201517      -0.372678      -0.27589   -0.265511     0.787752   \n",
            "2             -0.201517      -0.372678      -0.27589   -0.265511     0.787752   \n",
            "3             -0.201517      -0.372678      -0.27589   -0.265511    -1.269435   \n",
            "4             -0.201517      -0.372678      -0.27589   -0.265511    -1.269435   \n",
            "\n",
            "   size_MINIMUM  \n",
            "0      1.536443  \n",
            "1     -0.650854  \n",
            "2     -0.650854  \n",
            "3      1.536443  \n",
            "4      1.536443  \n",
            "(410, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Definir el modelo como función de hp\n",
        "def build_model(hp, input_dim):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(\n",
        "        units=hp.Int(\"units_1\", min_value=64, max_value=256, step=32),\n",
        "        activation=\"relu\",\n",
        "        input_shape=(input_dim,)\n",
        "    ))\n",
        "    model.add(Dropout(hp.Float(\"dropout\", min_value=0.1, max_value=0.5, step=0.1)))\n",
        "    model.add(Dense(\n",
        "        units=hp.Int(\"units_2\", min_value=16, max_value=128, step=16),\n",
        "        activation=\"relu\"\n",
        "    ))\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    lr = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
        "    model.compile(optimizer=Adam(learning_rate=lr), loss=\"mse\", metrics=[\"mae\"])\n",
        "    return model"
      ],
      "metadata": {
        "id": "zpyuTPwwno7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) Tuner con VALIDACIÓN CRUZADA (K-Fold)\n",
        "#    Subclasificando RandomSearch para hacer CV\n",
        "class CVRandomSearch(kt.tuners.RandomSearch):\n",
        "    def __init__(self, X, y, kf, epochs=100, patience=10, verbose=0, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.kf = kf\n",
        "        self.epochs = epochs\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "\n",
        "    def run_trial(self, trial, *args, **kwargs):\n",
        "        # Hyperparams para este trial\n",
        "        hp = trial.hyperparameters\n",
        "\n",
        "        # Batch size como hp (se usa en cada fit)\n",
        "        batch_size = hp.Choice(\"batch_size\", values=[16, 32, 64])\n",
        "\n",
        "        fold_maes, fold_losses = [], []\n",
        "\n",
        "        # K-Fold CV\n",
        "        for train_idx, val_idx in self.kf.split(self.X):\n",
        "            X_tr, X_val = self.X.iloc[train_idx], self.X.iloc[val_idx]\n",
        "            y_tr, y_val = self.y.iloc[train_idx], self.y.iloc[val_idx]\n",
        "\n",
        "            model = build_model(hp, input_dim=X_tr.shape[1])\n",
        "            early_stop = EarlyStopping(\n",
        "                monitor=\"val_loss\", patience=self.patience, restore_best_weights=True\n",
        "            )\n",
        "\n",
        "            history = model.fit(\n",
        "                X_tr, y_tr,\n",
        "                validation_data=(X_val, y_val),\n",
        "                epochs=self.epochs,\n",
        "                batch_size=batch_size,\n",
        "                callbacks=[early_stop],\n",
        "                verbose=self.verbose\n",
        "            )\n",
        "\n",
        "            # Evaluar en el fold\n",
        "            loss, mae = model.evaluate(X_val, y_val, verbose=0)\n",
        "            fold_losses.append(loss)\n",
        "            fold_maes.append(mae)\n",
        "\n",
        "        # Promedios de CV para objetivo del tuner\n",
        "        mean_loss = float(np.mean(fold_losses))\n",
        "        mean_mae  = float(np.mean(fold_maes))\n",
        "\n",
        "        # Reportar métricas al Oracle (usamos val_mae como objetivo)\n",
        "        self.oracle.update_trial(\n",
        "            trial.trial_id,\n",
        "            metrics={\"val_loss\": mean_loss, \"val_mae\": mean_mae}\n",
        "        )\n",
        "        # self.save_model(trial.trial_id, model)  # opcional"
      ],
      "metadata": {
        "id": "jvwreEM7nx_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3) Ejecutar RandomSearch con CV\n",
        "\n",
        "N_SPLITS = 5\n",
        "kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
        "\n",
        "tuner = CVRandomSearch(\n",
        "    X=X_train,\n",
        "    y=y_train,\n",
        "    kf=kf,\n",
        "    epochs=100,\n",
        "    patience=10,\n",
        "    verbose=0,\n",
        "    hypermodel=lambda hp: build_model(hp, input_dim=X_train.shape[1]),\n",
        "    objective=kt.Objective(\"val_mae\", direction=\"min\"),\n",
        "    max_trials=20,                 # <-- ajusta cuántas combinaciones aleatorias probar\n",
        "    executions_per_trial=1,\n",
        "    directory=\"tuner_dir\",\n",
        "    project_name=\"regresion_peso_randomcv\"\n",
        ")\n",
        "\n",
        "tuner.search()  # ¡lanza la búsqueda!\n",
        "\n",
        "best_hp = tuner.get_best_hyperparameters(1)[0]\n",
        "print(\"\\n=== Mejores hiperparámetros (RandomSearch + CV) ===\")\n",
        "for k, v in best_hp.values.items():\n",
        "    print(f\"{k}: {v}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1WtSdLrpjha",
        "outputId": "0d7cc7c1-1d02-4849-8111-31515c2e55f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 20 Complete [00h 00m 58s]\n",
            "val_mae: 15.367775154113769\n",
            "\n",
            "Best val_mae So Far: 10.968683624267578\n",
            "Total elapsed time: 00h 21m 30s\n",
            "\n",
            "=== Mejores hiperparámetros (RandomSearch + CV) ===\n",
            "units_1: 192\n",
            "dropout: 0.1\n",
            "units_2: 112\n",
            "lr: 0.0020779711721873807\n",
            "batch_size: 16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4) Entrenamiento cruzado final con hp óptimos\n",
        "#    y métricas por fold: MAE, MSE, RMSE, R²\n",
        "\n",
        "EPOCHS_FINAL = 100\n",
        "PATIENCE_FINAL = 10\n",
        "VERBOSE_FINAL = 0\n",
        "\n",
        "def build_model_from_hp(hp, input_dim):\n",
        "    # Helper para reconstruir desde best_hp\n",
        "    model = Sequential([\n",
        "        Dense(hp.get(\"units_1\"), activation=\"relu\", input_shape=(input_dim,)),\n",
        "        Dropout(hp.get(\"dropout\")),\n",
        "        Dense(hp.get(\"units_2\"), activation=\"relu\"),\n",
        "        Dense(1)\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=hp.get(\"lr\")), loss=\"mse\", metrics=[\"mae\"])\n",
        "    return model\n",
        "\n",
        "metrics_per_fold = []\n",
        "\n",
        "print(\"\\n=== ENTRENAMIENTO FINAL (K-Fold) CON MEJORES HP ===\")\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train), start=1):\n",
        "    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
        "    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
        "\n",
        "    model = build_model_from_hp(best_hp, input_dim=X_tr.shape[1])\n",
        "    early_stop = EarlyStopping(monitor=\"val_loss\", patience=PATIENCE_FINAL, restore_best_weights=True)\n",
        "\n",
        "    history = model.fit(\n",
        "        X_tr, y_tr,\n",
        "        validation_data=(X_val, y_val),\n",
        "        epochs=EPOCHS_FINAL,\n",
        "        batch_size=best_hp.get(\"batch_size\"),\n",
        "        callbacks=[early_stop],\n",
        "        verbose=VERBOSE_FINAL\n",
        "    )\n",
        "\n",
        "    y_val_pred = model.predict(X_val, verbose=0).reshape(-1)\n",
        "\n",
        "    mae  = mean_absolute_error(y_val, y_val_pred)\n",
        "    mse  = mean_squared_error(y_val, y_val_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2   = r2_score(y_val, y_val_pred)\n",
        "\n",
        "    metrics_per_fold.append({\n",
        "        \"fold\": fold,\n",
        "        \"MAE\": mae,\n",
        "        \"MSE\": mse,\n",
        "        \"RMSE\": rmse,\n",
        "        \"R2\": r2\n",
        "    })\n",
        "\n",
        "    print(f\"Fold {fold} -> MAE: {mae:.5f} | MSE: {mse:.5f} | RMSE: {rmse:.5f} | R²: {r2:.5f}\")\n",
        "\n",
        "metrics_df = pd.DataFrame(metrics_per_fold)\n",
        "metrics_mean = metrics_df[[\"MAE\",\"MSE\",\"RMSE\",\"R2\"]].mean().to_dict()\n",
        "\n",
        "print(\"\\n=== RESUMEN MÉTRICAS POR FOLD (VAL) ===\")\n",
        "print(metrics_df)\n",
        "print(\"\\n=== PROMEDIO MÉTRICAS (VAL) ===\")\n",
        "for k, v in metrics_mean.items():\n",
        "    print(f\"{k}: {v:.6f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uErjxI0Vpo5w",
        "outputId": "6c24e70b-7be4-4d8f-d324-4ee33643a128"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== ENTRENAMIENTO FINAL (K-Fold) CON MEJORES HP ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 -> MAE: 5.51568 | MSE: 77.57510 | RMSE: 8.80767 | R²: 0.97372\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 -> MAE: 14.71291 | MSE: 766.66571 | RMSE: 27.68873 | R²: 0.89027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "WARNING:tensorflow:5 out of the last 7 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7eb789410680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7eb789410680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 -> MAE: 10.28100 | MSE: 422.45459 | RMSE: 20.55370 | R²: 0.91831\n",
            "Fold 4 -> MAE: 21.36312 | MSE: 1165.94910 | RMSE: 34.14600 | R²: 0.82599\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 5 -> MAE: 10.11985 | MSE: 285.51968 | RMSE: 16.89733 | R²: 0.96319\n",
            "\n",
            "=== RESUMEN MÉTRICAS POR FOLD (VAL) ===\n",
            "   fold        MAE          MSE       RMSE        R2\n",
            "0     1   5.515679    77.575104   8.807673  0.973717\n",
            "1     2  14.712910   766.665710  27.688729  0.890270\n",
            "2     3  10.280997   422.454590  20.553700  0.918311\n",
            "3     4  21.363119  1165.949097  34.145997  0.825986\n",
            "4     5  10.119851   285.519684  16.897328  0.963193\n",
            "\n",
            "=== PROMEDIO MÉTRICAS (VAL) ===\n",
            "MAE: 12.398511\n",
            "MSE: 543.632837\n",
            "RMSE: 21.618685\n",
            "R2: 0.914295\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5) Reentrenar en TODO el train y evaluar en TEST\n",
        "\n",
        "final_model = build_model_from_hp(best_hp, input_dim=X_train.shape[1])\n",
        "early_stop_full = EarlyStopping(monitor=\"val_loss\", patience=PATIENCE_FINAL, restore_best_weights=True)\n",
        "\n",
        "_ = final_model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_split=0.1,\n",
        "    epochs=EPOCHS_FINAL,\n",
        "    batch_size=best_hp.get(\"batch_size\"),\n",
        "    callbacks=[early_stop_full],\n",
        "    verbose=VERBOSE_FINAL\n",
        ")\n",
        "\n",
        "# --- Gráfica de pérdidas ---\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(history.history[\"loss\"], label=\"Pérdida de entrenamiento\")\n",
        "plt.plot(history.history[\"val_loss\"], label=\"Pérdida de validación\")\n",
        "plt.title(\"Evolución de la pérdida (loss)\")\n",
        "plt.xlabel(\"Épocas\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "y_test_pred = final_model.predict(X_test, verbose=0).reshape(-1)\n",
        "\n",
        "test_mae  = mean_absolute_error(y_test, y_test_pred)\n",
        "test_mse  = mean_squared_error(y_test, y_test_pred)\n",
        "test_rmse = np.sqrt(test_mse)\n",
        "test_r2   = r2_score(y_test, y_test_pred)\n",
        "\n",
        "print(\"\\n=== MÉTRICAS EN TEST ===\")\n",
        "print(f\"MAE:  {test_mae:.6f}\")\n",
        "print(f\"MSE:  {test_mse:.6f}\")\n",
        "print(f\"RMSE: {test_rmse:.6f}\")\n",
        "print(f\"R²:   {test_r2:.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyj-VGKJpuKP",
        "outputId": "9beee5dd-8158-4f85-9c0b-f082b7e16c54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== MÉTRICAS EN TEST ===\n",
            "MAE:  19.666269\n",
            "MSE:  962.298828\n",
            "RMSE: 31.020942\n",
            "R²:   0.728298\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3293b40e",
        "outputId": "c34106f3-e35d-46b3-f13a-c3279a522900"
      },
      "source": [
        "%pip install keras-tuner -q"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    }
  ]
}